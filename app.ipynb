{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e998619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.custom_dataset import CustomDataset\n",
    "from scripts.vectorizer import Seq2Seq_Vectorizer\n",
    "from scripts.tokenizer import SeparatorTokenizer\n",
    "from scripts.vocabulary import Vocabulary\n",
    "from scripts.model import Seq2Seq_Model\n",
    "\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import pandas\n",
    "import time\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745196c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROPORTION = 0.0\n",
    "EVAL_PROPORTION = 0.2\n",
    "\n",
    "TOKENS_TRESHOLD_FREQ = 10\n",
    "\n",
    "SHUFFLE = True\n",
    "DROP_LAST = True\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "SAMPLE_PROBABILITY = 0.1 # Вероятность при обучении взять в качестве input сгенерированный токен, а не groung-truth токен\n",
    "\n",
    "LR_SCHEDULER_FACTOR = 0.5\n",
    "LR_SCHEDULER_PATIENCE = 2\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "SOURCE_EMBEDDING_SIZE = 48\n",
    "TARGET_EMBEDDING_SIZE = 48\n",
    "MAX_SOURCE_SEQ_LEN = 100\n",
    "MAX_TARGET_SEQ_LEN = 114\n",
    "MAX_GENERATED_SEQ_LEN = 114\n",
    "\n",
    "RNN_HIDDEN_SIZE = 64\n",
    "FC_HIDDEN_SIZE = 256\n",
    "\n",
    "MODEL_SAVE_FILEPATH = 'data/model_params.pt'\n",
    "DATASET_PATH = 'D:/Files/Datasets/NMT_ru_en'\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac96e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d8df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32492a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device='cpu'):\n",
    "    '''Перенос данных на device и подготовка к упаковке в padded_seq'''\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle, drop_last=drop_last)\n",
    "    for data_dict in dataloader:\n",
    "        lengths = data_dict['source_len'].numpy()\n",
    "        sorted_length_indices = lengths.argsort()[::-1].tolist()\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918b42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.reshape(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.reshape(-1)\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59a20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21469582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a1838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_freq(dataframe : pandas.DataFrame) -> tuple[dict, dict]:\n",
    "    '''Принимает токенизированный датафрейм'''\n",
    "    source_freq = {}\n",
    "    target_freq = {}\n",
    "    for i in range(len(dataframe)):\n",
    "        source_tokens, target_tokens = (dataframe.loc[i, 'source_text'], dataframe.loc[i, 'target_text'])\n",
    "        for token in source_tokens:\n",
    "            if token in source_freq:\n",
    "                source_freq[token] += 1\n",
    "            else:\n",
    "                source_freq[token] = 1\n",
    "        for token in target_tokens:\n",
    "            if token in target_freq:\n",
    "                target_freq[token] += 1\n",
    "            else:\n",
    "                target_freq[token] = 1\n",
    "    return source_freq, target_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8912167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_tokenized_seq_len(dataframe : pandas.DataFrame) -> tuple[int, int]:\n",
    "    '''Принимает датафрейм с токенизированными текстами.\n",
    "    Возвращает два списка: длина исходных текстов, длина таргет текстов'''\n",
    "    source_max_len = target_max_len = -1\n",
    "    for idx in range(len(dataframe)):\n",
    "        source_max_len = max(len(dataframe.loc[idx, 'source_text']), source_max_len)\n",
    "        target_max_len = max(len(dataframe.loc[idx, 'target_text']), target_max_len)\n",
    "    return source_max_len, target_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43da206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, vectorizer, query: str, max_response_tokens:int=50, response_seq_count : int = 1, temperature: float = 1.0, device='cpu') -> str:\n",
    "    \"\"\"Генерирует ответ на входной запрос\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Токенизация и векторизация\n",
    "        tokens = tokenizer.tokenize(query.lower())\n",
    "        vec_dict = vectorizer.vectorize(source_tokens=tokens, use_dataset_max_len=False)\n",
    "\n",
    "        source_vec = torch.tensor(vec_dict['source_vec'], dtype=torch.long).to(device).unsqueeze(0)\n",
    "        # print(f'source_vec.size() {source_vec.size()}')\n",
    "        source_len = torch.tensor([vec_dict['source_len']], dtype=torch.long).to(device)\n",
    "        # print(f'source_len.size() {source_len.size()}')\n",
    "\n",
    "        # Encoder\n",
    "        encoder_state, encoder_final_hidden = model.encoder(source_vec, source_len)\n",
    "\n",
    "        # Decoder\n",
    "        decoded_states = model.decoder(encoder_state, encoder_final_hidden, forced_batch_size=response_seq_count,\\\n",
    "                                    sample_probability=1.0, output_sequence_size=max_response_tokens, temperature=temperature)\n",
    "        \n",
    "        batch_size, seq_size, vocab_size = decoded_states.size()\n",
    "        decoded_states = F.softmax(decoded_states * temperature, dim=-1)\n",
    "        print(f'decoded_states.size() {decoded_states.size()}')\n",
    "        decoded_states = decoded_states.reshape(-1, vocab_size)\n",
    "        indices = torch.multinomial(decoded_states, 1)\n",
    "        print(f'indices.size() {indices.size()}')\n",
    "        indices = indices.reshape(batch_size, seq_size, -1).squeeze(-1)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49240e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_indices(indices : torch.tensor, vectorizer):\n",
    "    seq_count, seq_len = (indices.size(0), indices.size(1))\n",
    "    vocab = vectorizer.target_vocab\n",
    "    decoded = []\n",
    "    for seq in range(seq_count):\n",
    "        string =''\n",
    "        for idx in range(seq_len):\n",
    "            index = indices[seq, idx].item()\n",
    "            if index != vocab.mask_token_index:\n",
    "                string += vocab.get_token(index) + ' '\n",
    "            if index == vocab._eos_index:\n",
    "                break\n",
    "        decoded.append(string)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb1c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filepath):\n",
    "    torch.save(model, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32688bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(os.path.join(DATASET_PATH, 'train.csv'))\n",
    "# test_df = pd.read_csv(os.path.join(DATASET_PATH, 'test.csv'))\n",
    "# validation_df = pd.read_csv(os.path.join(DATASET_PATH, 'validation.csv'))\n",
    "# df = pd.concat([train_df, test_df, validation_df], ignore_index=True)\n",
    "# del train_df, test_df, validation_df\n",
    "# gc.collect()\n",
    "# test_valid_len = (TEST_PROPORTION + EVAL_PROPORTION) * len(df)\n",
    "# test_valid_proportion = TEST_PROPORTION / EVAL_PROPORTION\n",
    "# valid_len = test_valid_len / (test_valid_proportion + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6852d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SeparatorTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094924f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_PATH, 'ru_en_small.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "df = df.rename(columns={'ru_text' : 'source_text', 'en_text' : 'target_text'})\n",
    "df['split'] = 'train'\n",
    "selected_indices = df.sample(int(EVAL_PROPORTION*len(df)), random_state=RANDOM_STATE).index\n",
    "df.loc[selected_indices, 'split'] = 'validation'\n",
    "\n",
    "# К нижнему регистру, токенизация и очистка от служебных символов\n",
    "df['source_text'] = df['source_text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['target_text'] = df['target_text'].apply(lambda x: tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afcf383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск максимальной длины сурс и таргет текста\n",
    "# source_max_len = target_max_len = -1\n",
    "# for i in range(len(df)):\n",
    "#     source_max_len = max(source_max_len, len(df.loc[i, 'source_text']))\n",
    "#     target_max_len = max(target_max_len, len(df.loc[i, 'target_text']))\n",
    "# print(source_max_len)\n",
    "# print(target_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb99cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_vocab = Vocabulary()\n",
    "# target_vocab = Vocabulary()\n",
    "\n",
    "# source_freq, target_freq = get_tokens_freq(df)\n",
    "\n",
    "# for key, value in source_freq.items():\n",
    "#     if value > TOKENS_TRESHOLD_FREQ:\n",
    "#         source_vocab.add_token(key)\n",
    "\n",
    "# for key, value in target_freq.items():\n",
    "#     if value > TOKENS_TRESHOLD_FREQ:\n",
    "#         target_vocab.add_token(key)\n",
    "\n",
    "\n",
    "# source_vocab.to_json('data/source_vocab.json')\n",
    "# target_vocab.to_json('data/target_vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4a81e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = Vocabulary.from_json('data/source_vocab.json')\n",
    "target_vocab = Vocabulary.from_json('data/target_vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b390ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Seq2Seq_Vectorizer(source_vocab, target_vocab, MAX_SOURCE_SEQ_LEN, MAX_TARGET_SEQ_LEN)\n",
    "dataset = CustomDataset(df, tokenizer, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c640f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab_size = len(source_vocab)\n",
    "target_vocab_size = len(target_vocab)\n",
    "mask_index = target_vocab.mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a628c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Seq2Seq_Model(source_vocab_size=source_vocab_size, source_embedding_size=SOURCE_EMBEDDING_SIZE, target_vocab_size=target_vocab_size,\\\n",
    "#                       target_embedding_size=TARGET_EMBEDDING_SIZE, encoder_rnn_size=RNN_HIDDEN_SIZE, fc_hidden_size=FC_HIDDEN_SIZE, target_bos_index=target_vocab._bos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16bbd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_SAVE_FILEPATH, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62366ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=LR_SCHEDULER_FACTOR, patience=LR_SCHEDULER_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff36bbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "epoch 0\n",
      "train_epoch_error 628.306847691536\n",
      "train loss 1.108124951836924   ,   train accuracy 75.7058709873725\n",
      "validation_epoch_error 171.15854215621948\n",
      "validation loss 1.2138903699022652   ,   validation accuracy 74.52440686136109\n",
      "----------------------------------------\n",
      "epoch 1\n",
      "train_epoch_error 612.3889297246933\n",
      "train loss 1.0800510224421398   ,   train accuracy 76.1120352127147\n",
      "validation_epoch_error 167.27371227741241\n",
      "validation loss 1.1863383849461873   ,   validation accuracy 75.09344233968358\n",
      "----------------------------------------\n",
      "epoch 2\n",
      "train_epoch_error 592.5762699246407\n",
      "train loss 1.0451080598318185   ,   train accuracy 76.73636551526334\n",
      "validation_epoch_error 166.83759319782257\n",
      "validation loss 1.183245341828529   ,   validation accuracy 75.0952107592785\n",
      "----------------------------------------\n",
      "epoch 3\n",
      "train_epoch_error 579.8028958439827\n",
      "train loss 1.0225800632168998   ,   train accuracy 77.11520416647426\n",
      "validation_epoch_error 161.297181725502\n",
      "validation loss 1.1439516434432766   ,   validation accuracy 75.84067311620943\n",
      "----------------------------------------\n",
      "epoch 4\n",
      "train_epoch_error 571.2695949673653\n",
      "train loss 1.00753014985426   ,   train accuracy 77.36394484396924\n",
      "validation_epoch_error 159.81940871477127\n",
      "validation loss 1.1334709837927037   ,   validation accuracy 76.18266595192803\n",
      "----------------------------------------\n",
      "epoch 5\n",
      "train_epoch_error 552.8002098798752\n",
      "train loss 0.9749562784477519   ,   train accuracy 77.91979509505741\n",
      "validation_epoch_error 157.00638139247894\n",
      "validation loss 1.1135204354076522   ,   validation accuracy 76.46100119203389\n",
      "----------------------------------------\n",
      "epoch 6\n",
      "train_epoch_error 549.975290954113\n",
      "train loss 0.9699740581201298   ,   train accuracy 77.96142081906619\n",
      "validation_epoch_error 156.1770077943802\n",
      "validation loss 1.1076383531516327   ,   validation accuracy 76.62680155643748\n",
      "----------------------------------------\n",
      "epoch 7\n",
      "train_epoch_error 538.9626730084419\n",
      "train loss 0.9505514515140073   ,   train accuracy 78.29560282707601\n",
      "validation_epoch_error 155.9019479751587\n",
      "validation loss 1.1056875742919052   ,   validation accuracy 76.6222708633974\n",
      "----------------------------------------\n",
      "epoch 8\n",
      "train_epoch_error 527.6425204873085\n",
      "train loss 0.9305864558859063   ,   train accuracy 78.6849138756338\n",
      "validation_epoch_error 154.53315556049347\n",
      "validation loss 1.0959798266701668   ,   validation accuracy 76.81521619788325\n",
      "----------------------------------------\n",
      "epoch 9\n",
      "train_epoch_error 518.9180532693863\n",
      "train loss 0.9151993884821624   ,   train accuracy 78.95339645866177\n",
      "validation_epoch_error 151.08436048030853\n",
      "validation loss 1.0715202870943865   ,   validation accuracy 77.32178808659593\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        sample_probability = SAMPLE_PROBABILITY\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_dataframe_split('train')\n",
    "        batch_generator = generate_batches(dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE, drop_last=DROP_LAST, device=DEVICE)\n",
    "        train_running_loss = 0.0\n",
    "        train_running_acc = 0.0\n",
    "        epoch_err = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute the output\n",
    "            y_pred = model(batch_dict['source_vec'],\n",
    "                           batch_dict['source_len'],\n",
    "                           batch_dict['target_x_vec'],\n",
    "                           sample_probability=sample_probability)\n",
    "\n",
    "            # compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict['target_y_vec'], mask_index=mask_index)\n",
    "\n",
    "            # use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "\n",
    "            # compute the running loss and running accuracy\n",
    "            train_running_loss += (loss.item() - train_running_loss) / (batch_index + 1)\n",
    "            epoch_err += loss.item()\n",
    "\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['target_y_vec'], mask_index)\n",
    "            train_running_acc += (acc_t - train_running_acc) / (batch_index + 1)\n",
    "\n",
    "        print('-'*40)\n",
    "        print(f'epoch {epoch}')\n",
    "        print(f'train_epoch_error {epoch_err}')\n",
    "        print(f'train loss {train_running_loss}   ,   train accuracy {train_running_acc}')\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_dataframe_split('validation')\n",
    "        batch_generator = generate_batches(dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE, drop_last=DROP_LAST, device=DEVICE)\n",
    "        valid_running_loss = 0.0\n",
    "        valid_running_acc = 0.0\n",
    "        epoch_err = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = model(batch_dict['source_vec'],\n",
    "                           batch_dict['source_len'],\n",
    "                           batch_dict['target_x_vec'],\n",
    "                           sample_probability=sample_probability)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict['target_y_vec'], mask_index)\n",
    "\n",
    "            # compute the running loss and accuracy\n",
    "            valid_running_loss += (loss.item() - valid_running_loss) / (batch_index + 1)\n",
    "            epoch_err += loss.item()\n",
    "\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['target_y_vec'], mask_index)\n",
    "            valid_running_acc += (acc_t - valid_running_acc) / (batch_index + 1)\n",
    "\n",
    "        print(f'validation_epoch_error {epoch_err}')\n",
    "        print(f'validation loss {valid_running_loss}   ,   validation accuracy {valid_running_acc}')\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a1de075",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Я хочу кушать бургеры и пить кока колу ночью'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5dccbc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded_states.size() torch.Size([1, 114, 4882])\n",
      "indices.size() torch.Size([114, 1])\n"
     ]
    }
   ],
   "source": [
    "indices = generate(model, tokenizer, vectorizer, query, max_response_tokens=MAX_GENERATED_SEQ_LEN, response_seq_count=1, device=DEVICE)\n",
    "response = decode_indices(indices, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b953a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i want the airplanes and . take are the marriage night . <EOS> ']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f214eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_to_file(model, MODEL_SAVE_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6945d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
